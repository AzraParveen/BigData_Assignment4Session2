components of Hadoop framework

1. HDFS:

HDFS stands for Hadoop Distributed File System for managing big data sets with High Volume, 
Velocity and Variety. HDFS implements master slave architecture. Master is Name node and slave is data node.

Features:
	Scalable
  Reliable
  Commodity Hardware
HDFS is the well known for Big Data storage.

2. Map Reduce:

Map Reduce is a programming model designed to process high volume distributed data. Platform is built using
Java for better exception handling. Map Reduce includes two deamons, Job tracker and Task Tracker.

Features:
  Functional Programming
  Works very well on Big Data
  Can process large datasets
Map Reduce is the main component known for processing big data.

3.YARN:
YARN stands for Yet Another Resource Negotiator. It is also called as MapReduce . The two major functionalities 
of Job Tracker in MRv1, resource management and job scheduling/ monitoring are split into separate daemons which
are ResourceManager, NodeManager and ApplicationMaster.

Features:
  Better resource management
  Scalability
  Dynamic allocation of cluster resources
